{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ulphidius/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ulphidius/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ulphidius/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ulphidius/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ulphidius/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ulphidius/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ulphidius/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ulphidius/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ulphidius/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ulphidius/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ulphidius/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ulphidius/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "1.0.4\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# split function for training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import sequential layer generator && layer data\n",
    "# Import Dense layer (all input on the current layer)\n",
    "# Import Model \n",
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Diplay data lib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Image handler lib \n",
    "from PIL import Image\n",
    "\n",
    "print(tf.__version__)\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder_name = 'pokemon_so_deep/result/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type_1</th>\n",
       "      <th>type_2</th>\n",
       "      <th>sprite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Charmeleon</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>005.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>Drakloak</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>886.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>Dragapult</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>887.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>Zacian</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>Steel</td>\n",
       "      <td>888.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>Zamazenta</td>\n",
       "      <td>Fighting</td>\n",
       "      <td>Steel</td>\n",
       "      <td>889.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Eternatus</td>\n",
       "      <td>Poison</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>890.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>890 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name    type_1  type_2   sprite\n",
       "0     Bulbasaur     Grass  Poison  001.png\n",
       "1       Ivysaur     Grass  Poison  002.png\n",
       "2      Venusaur     Grass  Poison  003.png\n",
       "3    Charmander      Fire     NaN  004.png\n",
       "4    Charmeleon      Fire     NaN  005.png\n",
       "..          ...       ...     ...      ...\n",
       "885    Drakloak    Dragon   Ghost  886.png\n",
       "886   Dragapult    Dragon   Ghost  887.png\n",
       "887      Zacian     Fairy   Steel  888.png\n",
       "888   Zamazenta  Fighting   Steel  889.png\n",
       "889   Eternatus    Poison  Dragon  890.png\n",
       "\n",
       "[890 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV labels\n",
    "labels = pd.read_csv('pokemon_so_deep/pokemon.csv', delimiter = ';')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_1</th>\n",
       "      <th>type_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>Dragon</td>\n",
       "      <td>Ghost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>Dragon</td>\n",
       "      <td>Ghost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>Fairy</td>\n",
       "      <td>Steel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>Fighting</td>\n",
       "      <td>Steel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>Poison</td>\n",
       "      <td>Dragon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>890 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       type_1  type_2\n",
       "0       Grass  Poison\n",
       "1       Grass  Poison\n",
       "2       Grass  Poison\n",
       "3        Fire     NaN\n",
       "4        Fire     NaN\n",
       "..        ...     ...\n",
       "885    Dragon   Ghost\n",
       "886    Dragon   Ghost\n",
       "887     Fairy   Steel\n",
       "888  Fighting   Steel\n",
       "889    Poison  Dragon\n",
       "\n",
       "[890 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokemon_types = labels[['type_1', 'type_2']]\n",
    "pokemon_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input data\n",
    "list_of_images = []\n",
    "\n",
    "for label_sprite in labels['sprite'] :\n",
    "    file = Image.open(images_folder_name + label_sprite)\n",
    "\n",
    "    # Virer alpha\n",
    "    file = file.convert('RGB')\n",
    "    data = np.array( file, dtype='uint8' )\n",
    "    \n",
    "    # Flatten\n",
    "    data_reshape = data.reshape(-1)\n",
    "    \n",
    "    # Divide by pixel\n",
    "    data_reshape_by_pixel = data_reshape / 255\n",
    "    \n",
    "    list_of_images.append(data_reshape_by_pixel)\n",
    "\n",
    "list_of_images = np.array(list_of_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ulphidius/.local/lib/python3.7/site-packages/pandas/core/frame.py:4153: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n",
      "/home/ulphidius/miniconda3/envs/machine_learning/lib/python3.7/site-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/ulphidius/miniconda3/envs/machine_learning/lib/python3.7/site-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_1</th>\n",
       "      <th>type_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>890 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type_1  type_2\n",
       "0         9      13\n",
       "1         9      13\n",
       "2         9      13\n",
       "3         6      18\n",
       "4         6      18\n",
       "..      ...     ...\n",
       "885       2       8\n",
       "886       2       8\n",
       "887       4      16\n",
       "888       5      16\n",
       "889      13       2\n",
       "\n",
       "[890 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input dico for all types (dataframe)\n",
    "pokemon_types_number_dic = {\n",
    "    'Bug' : 0,\n",
    "    'Dark' : 1,\n",
    "    'Dragon' : 2,\n",
    "    'Electric' : 3,\n",
    "    'Fairy' : 4,\n",
    "    'Fighting' : 5,\n",
    "    'Fire' : 6,\n",
    "    'Flying' : 7,\n",
    "    'Ghost' : 8,\n",
    "    'Grass' : 9,\n",
    "    'Ground' : 10,\n",
    "    'Ice' : 11,\n",
    "    'Normal' : 12,\n",
    "    'Poison' : 13,\n",
    "    'Psychic' : 14,\n",
    "    'Rock' : 15,\n",
    "    'Steel' : 16,\n",
    "    'Water' : 17,\n",
    "    18 : 18\n",
    "}\n",
    "\n",
    "pokemon_types.fillna(18, inplace = True)\n",
    "\n",
    "pokemon_types['type_1'] = pokemon_types.type_1.apply(lambda x: pokemon_types_number_dic[x])\n",
    "pokemon_types['type_2'] = pokemon_types.type_2.apply(lambda x: pokemon_types_number_dic[x])\n",
    "\n",
    "pokemon_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output data\n",
    "output_array = []\n",
    "for index, pokemon_type in pokemon_types.iterrows() :\n",
    "    type_array = np.zeros(19)\n",
    "    type_array[pokemon_type['type_1']] = 1\n",
    "    #type_array[pokemon_type['type_2']] = 1\n",
    "    output_array.append(type_array)\n",
    "\n",
    "output_array = np.array(output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data between test end train\n",
    "X_train, X_test, y_train, y_test = train_test_split(list_of_images, output_array, test_size = 0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ulphidius/.local/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Not working\n",
    "#model = Sequential()\n",
    "#model.add(Input(shape=(32, 32, 3)))\n",
    "#model.add(Dense(19, activation = 'softmax'))\n",
    "\n",
    "input_format = Input(shape=list_of_images[0].shape)\n",
    "invisible_layer_1 = Dense(15, activation = 'relu')(input_format)\n",
    "invisible_layer_2 = Dense(7, activation = 'relu')(invisible_layer_1)\n",
    "output_end = Dense(19, activation = 'softmax')(invisible_layer_2)\n",
    "model = Model(inputs=input_format, outputs=output_end)\n",
    "\n",
    "optimizer_custom = tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=0.0000001,\n",
    "    name=\"custom_rms\"\n",
    ")\n",
    "\n",
    "#tf.keras.optimizers.Adam(\n",
    "#    learning_rate=0.001,\n",
    "#    beta_1=0.9,\n",
    "#    beta_2=0.999,\n",
    "#    epsilon=1e-07,\n",
    "#    amsgrad=False,\n",
    "#    name=\"Adam\",\n",
    "#    **kwargs\n",
    "#)\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizer_custom, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 3072)]            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 15)                46095     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 112       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 19)                152       \n",
      "=================================================================\n",
      "Total params: 46,359\n",
      "Trainable params: 46,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 712 samples, validate on 178 samples\n",
      "Epoch 1/600\n",
      "712/712 [==============================] - 0s 210us/sample - loss: 3.0749 - acc: 0.0421 - val_loss: 3.0549 - val_acc: 0.0281\n",
      "Epoch 2/600\n",
      "712/712 [==============================] - 0s 74us/sample - loss: 3.0730 - acc: 0.0421 - val_loss: 3.0536 - val_acc: 0.0281\n",
      "Epoch 3/600\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 3.0713 - acc: 0.0421 - val_loss: 3.0523 - val_acc: 0.0225\n",
      "Epoch 4/600\n",
      "712/712 [==============================] - 0s 76us/sample - loss: 3.0697 - acc: 0.0421 - val_loss: 3.0511 - val_acc: 0.0225\n",
      "Epoch 5/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 3.0681 - acc: 0.0421 - val_loss: 3.0498 - val_acc: 0.0225\n",
      "Epoch 6/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 3.0665 - acc: 0.0421 - val_loss: 3.0487 - val_acc: 0.0225\n",
      "Epoch 7/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 3.0650 - acc: 0.0421 - val_loss: 3.0476 - val_acc: 0.0225\n",
      "Epoch 8/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 3.0634 - acc: 0.0435 - val_loss: 3.0464 - val_acc: 0.0225\n",
      "Epoch 9/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 3.0618 - acc: 0.0435 - val_loss: 3.0452 - val_acc: 0.0225\n",
      "Epoch 10/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 3.0603 - acc: 0.0435 - val_loss: 3.0440 - val_acc: 0.0225\n",
      "Epoch 11/600\n",
      "712/712 [==============================] - 0s 68us/sample - loss: 3.0587 - acc: 0.0435 - val_loss: 3.0428 - val_acc: 0.0225\n",
      "Epoch 12/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 3.0573 - acc: 0.0435 - val_loss: 3.0417 - val_acc: 0.0281\n",
      "Epoch 13/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 3.0558 - acc: 0.0435 - val_loss: 3.0406 - val_acc: 0.0281\n",
      "Epoch 14/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 3.0542 - acc: 0.0435 - val_loss: 3.0395 - val_acc: 0.0281\n",
      "Epoch 15/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 3.0529 - acc: 0.0435 - val_loss: 3.0384 - val_acc: 0.0281\n",
      "Epoch 16/600\n",
      "712/712 [==============================] - 0s 70us/sample - loss: 3.0514 - acc: 0.0435 - val_loss: 3.0374 - val_acc: 0.0337\n",
      "Epoch 17/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 3.0501 - acc: 0.0435 - val_loss: 3.0364 - val_acc: 0.0337\n",
      "Epoch 18/600\n",
      "712/712 [==============================] - 0s 69us/sample - loss: 3.0487 - acc: 0.0435 - val_loss: 3.0352 - val_acc: 0.0337\n",
      "Epoch 19/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 3.0472 - acc: 0.0435 - val_loss: 3.0342 - val_acc: 0.0337\n",
      "Epoch 20/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 3.0458 - acc: 0.0435 - val_loss: 3.0331 - val_acc: 0.0337\n",
      "Epoch 21/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 3.0444 - acc: 0.0435 - val_loss: 3.0320 - val_acc: 0.0337\n",
      "Epoch 22/600\n",
      "712/712 [==============================] - 0s 68us/sample - loss: 3.0430 - acc: 0.0435 - val_loss: 3.0310 - val_acc: 0.0337\n",
      "Epoch 23/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 3.0417 - acc: 0.0435 - val_loss: 3.0301 - val_acc: 0.0337\n",
      "Epoch 24/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 3.0404 - acc: 0.0435 - val_loss: 3.0291 - val_acc: 0.0337\n",
      "Epoch 25/600\n",
      "712/712 [==============================] - 0s 68us/sample - loss: 3.0390 - acc: 0.0435 - val_loss: 3.0281 - val_acc: 0.0337\n",
      "Epoch 26/600\n",
      "712/712 [==============================] - 0s 68us/sample - loss: 3.0377 - acc: 0.0435 - val_loss: 3.0271 - val_acc: 0.0393\n",
      "Epoch 27/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 3.0364 - acc: 0.0435 - val_loss: 3.0261 - val_acc: 0.0449\n",
      "Epoch 28/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 3.0351 - acc: 0.0435 - val_loss: 3.0253 - val_acc: 0.0449\n",
      "Epoch 29/600\n",
      "712/712 [==============================] - 0s 68us/sample - loss: 3.0339 - acc: 0.0421 - val_loss: 3.0243 - val_acc: 0.0449\n",
      "Epoch 30/600\n",
      "712/712 [==============================] - 0s 72us/sample - loss: 3.0326 - acc: 0.0421 - val_loss: 3.0234 - val_acc: 0.0449\n",
      "Epoch 31/600\n",
      "712/712 [==============================] - 0s 70us/sample - loss: 3.0313 - acc: 0.0421 - val_loss: 3.0225 - val_acc: 0.0506\n",
      "Epoch 32/600\n",
      "712/712 [==============================] - 0s 69us/sample - loss: 3.0302 - acc: 0.0421 - val_loss: 3.0216 - val_acc: 0.0506\n",
      "Epoch 33/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 3.0289 - acc: 0.0421 - val_loss: 3.0207 - val_acc: 0.0506\n",
      "Epoch 34/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 3.0277 - acc: 0.0421 - val_loss: 3.0199 - val_acc: 0.0506\n",
      "Epoch 35/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 3.0265 - acc: 0.0421 - val_loss: 3.0190 - val_acc: 0.0506\n",
      "Epoch 36/600\n",
      "712/712 [==============================] - 0s 69us/sample - loss: 3.0253 - acc: 0.0449 - val_loss: 3.0182 - val_acc: 0.0506\n",
      "Epoch 37/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 3.0241 - acc: 0.0435 - val_loss: 3.0173 - val_acc: 0.0506\n",
      "Epoch 38/600\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 3.0229 - acc: 0.0435 - val_loss: 3.0165 - val_acc: 0.0506\n",
      "Epoch 39/600\n",
      "712/712 [==============================] - 0s 98us/sample - loss: 3.0218 - acc: 0.0435 - val_loss: 3.0158 - val_acc: 0.0506\n",
      "Epoch 40/600\n",
      "712/712 [==============================] - 0s 102us/sample - loss: 3.0207 - acc: 0.0421 - val_loss: 3.0149 - val_acc: 0.0506\n",
      "Epoch 41/600\n",
      "712/712 [==============================] - 0s 77us/sample - loss: 3.0195 - acc: 0.0421 - val_loss: 3.0141 - val_acc: 0.0506\n",
      "Epoch 42/600\n",
      "712/712 [==============================] - 0s 74us/sample - loss: 3.0184 - acc: 0.0421 - val_loss: 3.0133 - val_acc: 0.0506\n",
      "Epoch 43/600\n",
      "712/712 [==============================] - 0s 72us/sample - loss: 3.0173 - acc: 0.0435 - val_loss: 3.0126 - val_acc: 0.0562\n",
      "Epoch 44/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 3.0162 - acc: 0.0421 - val_loss: 3.0118 - val_acc: 0.0562\n",
      "Epoch 45/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 3.0151 - acc: 0.0407 - val_loss: 3.0111 - val_acc: 0.0562\n",
      "Epoch 46/600\n",
      "712/712 [==============================] - 0s 71us/sample - loss: 3.0140 - acc: 0.0421 - val_loss: 3.0103 - val_acc: 0.0562\n",
      "Epoch 47/600\n",
      "712/712 [==============================] - 0s 72us/sample - loss: 3.0130 - acc: 0.0421 - val_loss: 3.0096 - val_acc: 0.0562\n",
      "Epoch 48/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 3.0118 - acc: 0.0421 - val_loss: 3.0088 - val_acc: 0.0562\n",
      "Epoch 49/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 3.0108 - acc: 0.0435 - val_loss: 3.0081 - val_acc: 0.0562\n",
      "Epoch 50/600\n",
      "712/712 [==============================] - 0s 68us/sample - loss: 3.0098 - acc: 0.0435 - val_loss: 3.0074 - val_acc: 0.0562\n",
      "Epoch 51/600\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 3.0088 - acc: 0.0449 - val_loss: 3.0067 - val_acc: 0.0562\n",
      "Epoch 52/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 3.0078 - acc: 0.0449 - val_loss: 3.0060 - val_acc: 0.0562\n",
      "Epoch 53/600\n",
      "712/712 [==============================] - 0s 111us/sample - loss: 3.0068 - acc: 0.0449 - val_loss: 3.0054 - val_acc: 0.0562\n",
      "Epoch 54/600\n",
      "712/712 [==============================] - 0s 96us/sample - loss: 3.0058 - acc: 0.0449 - val_loss: 3.0047 - val_acc: 0.0562\n",
      "Epoch 55/600\n",
      "712/712 [==============================] - 0s 102us/sample - loss: 3.0049 - acc: 0.0449 - val_loss: 3.0040 - val_acc: 0.0562\n",
      "Epoch 56/600\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 3.0039 - acc: 0.0449 - val_loss: 3.0034 - val_acc: 0.0562\n",
      "Epoch 57/600\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 3.0030 - acc: 0.0435 - val_loss: 3.0028 - val_acc: 0.0562\n",
      "Epoch 58/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 3.0021 - acc: 0.0435 - val_loss: 3.0021 - val_acc: 0.0562\n",
      "Epoch 59/600\n",
      "712/712 [==============================] - 0s 70us/sample - loss: 3.0012 - acc: 0.0435 - val_loss: 3.0015 - val_acc: 0.0562\n",
      "Epoch 60/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 65us/sample - loss: 3.0003 - acc: 0.0435 - val_loss: 3.0009 - val_acc: 0.0562\n",
      "Epoch 61/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9995 - acc: 0.0421 - val_loss: 3.0002 - val_acc: 0.0562\n",
      "Epoch 62/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9987 - acc: 0.0421 - val_loss: 2.9996 - val_acc: 0.0618\n",
      "Epoch 63/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9978 - acc: 0.0421 - val_loss: 2.9990 - val_acc: 0.0618\n",
      "Epoch 64/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9970 - acc: 0.0435 - val_loss: 2.9984 - val_acc: 0.0618\n",
      "Epoch 65/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9962 - acc: 0.0463 - val_loss: 2.9978 - val_acc: 0.0618\n",
      "Epoch 66/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9953 - acc: 0.0463 - val_loss: 2.9971 - val_acc: 0.0618\n",
      "Epoch 67/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9945 - acc: 0.0463 - val_loss: 2.9965 - val_acc: 0.0618\n",
      "Epoch 68/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9937 - acc: 0.0478 - val_loss: 2.9959 - val_acc: 0.0618\n",
      "Epoch 69/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9929 - acc: 0.0478 - val_loss: 2.9953 - val_acc: 0.0618\n",
      "Epoch 70/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9922 - acc: 0.0478 - val_loss: 2.9947 - val_acc: 0.0618\n",
      "Epoch 71/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9914 - acc: 0.0478 - val_loss: 2.9941 - val_acc: 0.0618\n",
      "Epoch 72/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9906 - acc: 0.0478 - val_loss: 2.9936 - val_acc: 0.0618\n",
      "Epoch 73/600\n",
      "712/712 [==============================] - 0s 59us/sample - loss: 2.9899 - acc: 0.0478 - val_loss: 2.9930 - val_acc: 0.0618\n",
      "Epoch 74/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9891 - acc: 0.0478 - val_loss: 2.9925 - val_acc: 0.0618\n",
      "Epoch 75/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9884 - acc: 0.0478 - val_loss: 2.9919 - val_acc: 0.0618\n",
      "Epoch 76/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9876 - acc: 0.0492 - val_loss: 2.9914 - val_acc: 0.0618\n",
      "Epoch 77/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9868 - acc: 0.0492 - val_loss: 2.9909 - val_acc: 0.0618\n",
      "Epoch 78/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9861 - acc: 0.0492 - val_loss: 2.9903 - val_acc: 0.0618\n",
      "Epoch 79/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9854 - acc: 0.0506 - val_loss: 2.9899 - val_acc: 0.0618\n",
      "Epoch 80/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9847 - acc: 0.0520 - val_loss: 2.9893 - val_acc: 0.0618\n",
      "Epoch 81/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9840 - acc: 0.0506 - val_loss: 2.9888 - val_acc: 0.0618\n",
      "Epoch 82/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9833 - acc: 0.0534 - val_loss: 2.9883 - val_acc: 0.0618\n",
      "Epoch 83/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9826 - acc: 0.0548 - val_loss: 2.9879 - val_acc: 0.0618\n",
      "Epoch 84/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9820 - acc: 0.0548 - val_loss: 2.9874 - val_acc: 0.0618\n",
      "Epoch 85/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9813 - acc: 0.0534 - val_loss: 2.9869 - val_acc: 0.0618\n",
      "Epoch 86/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9807 - acc: 0.0534 - val_loss: 2.9865 - val_acc: 0.0618\n",
      "Epoch 87/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9801 - acc: 0.0534 - val_loss: 2.9860 - val_acc: 0.0674\n",
      "Epoch 88/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9794 - acc: 0.0534 - val_loss: 2.9856 - val_acc: 0.0674\n",
      "Epoch 89/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9788 - acc: 0.0562 - val_loss: 2.9851 - val_acc: 0.0674\n",
      "Epoch 90/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9781 - acc: 0.0562 - val_loss: 2.9847 - val_acc: 0.0674\n",
      "Epoch 91/600\n",
      "712/712 [==============================] - 0s 59us/sample - loss: 2.9775 - acc: 0.0548 - val_loss: 2.9843 - val_acc: 0.0674\n",
      "Epoch 92/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9769 - acc: 0.0562 - val_loss: 2.9839 - val_acc: 0.0674\n",
      "Epoch 93/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9763 - acc: 0.0590 - val_loss: 2.9835 - val_acc: 0.0674\n",
      "Epoch 94/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9758 - acc: 0.0590 - val_loss: 2.9831 - val_acc: 0.0674\n",
      "Epoch 95/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9752 - acc: 0.0590 - val_loss: 2.9826 - val_acc: 0.0674\n",
      "Epoch 96/600\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 2.9747 - acc: 0.0576 - val_loss: 2.9823 - val_acc: 0.0674\n",
      "Epoch 97/600\n",
      "712/712 [==============================] - 0s 108us/sample - loss: 2.9741 - acc: 0.0576 - val_loss: 2.9819 - val_acc: 0.0674\n",
      "Epoch 98/600\n",
      "712/712 [==============================] - 0s 107us/sample - loss: 2.9736 - acc: 0.0576 - val_loss: 2.9815 - val_acc: 0.0674\n",
      "Epoch 99/600\n",
      "712/712 [==============================] - 0s 86us/sample - loss: 2.9730 - acc: 0.0590 - val_loss: 2.9812 - val_acc: 0.0674\n",
      "Epoch 100/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9725 - acc: 0.0590 - val_loss: 2.9808 - val_acc: 0.0674\n",
      "Epoch 101/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9720 - acc: 0.0590 - val_loss: 2.9805 - val_acc: 0.0674\n",
      "Epoch 102/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9715 - acc: 0.0618 - val_loss: 2.9801 - val_acc: 0.0674\n",
      "Epoch 103/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9710 - acc: 0.0618 - val_loss: 2.9798 - val_acc: 0.0674\n",
      "Epoch 104/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9706 - acc: 0.0646 - val_loss: 2.9795 - val_acc: 0.0674\n",
      "Epoch 105/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9701 - acc: 0.0660 - val_loss: 2.9791 - val_acc: 0.0674\n",
      "Epoch 106/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9697 - acc: 0.0674 - val_loss: 2.9788 - val_acc: 0.0674\n",
      "Epoch 107/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9692 - acc: 0.0688 - val_loss: 2.9785 - val_acc: 0.0674\n",
      "Epoch 108/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9687 - acc: 0.0702 - val_loss: 2.9782 - val_acc: 0.0730\n",
      "Epoch 109/600\n",
      "712/712 [==============================] - 0s 69us/sample - loss: 2.9683 - acc: 0.0716 - val_loss: 2.9778 - val_acc: 0.0730\n",
      "Epoch 110/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9679 - acc: 0.0716 - val_loss: 2.9776 - val_acc: 0.0730\n",
      "Epoch 111/600\n",
      "712/712 [==============================] - 0s 70us/sample - loss: 2.9675 - acc: 0.0716 - val_loss: 2.9772 - val_acc: 0.0730\n",
      "Epoch 112/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9670 - acc: 0.0716 - val_loss: 2.9769 - val_acc: 0.0787\n",
      "Epoch 113/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9666 - acc: 0.0716 - val_loss: 2.9766 - val_acc: 0.0843\n",
      "Epoch 114/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9662 - acc: 0.0730 - val_loss: 2.9764 - val_acc: 0.0843\n",
      "Epoch 115/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9658 - acc: 0.0744 - val_loss: 2.9761 - val_acc: 0.0843\n",
      "Epoch 116/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9654 - acc: 0.0772 - val_loss: 2.9758 - val_acc: 0.0787\n",
      "Epoch 117/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9650 - acc: 0.0772 - val_loss: 2.9756 - val_acc: 0.0787\n",
      "Epoch 118/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9647 - acc: 0.0758 - val_loss: 2.9753 - val_acc: 0.0843\n",
      "Epoch 119/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9642 - acc: 0.0758 - val_loss: 2.9751 - val_acc: 0.0843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9639 - acc: 0.0758 - val_loss: 2.9748 - val_acc: 0.0843\n",
      "Epoch 121/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9635 - acc: 0.0758 - val_loss: 2.9746 - val_acc: 0.0843\n",
      "Epoch 122/600\n",
      "712/712 [==============================] - 0s 59us/sample - loss: 2.9631 - acc: 0.0758 - val_loss: 2.9743 - val_acc: 0.0843\n",
      "Epoch 123/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9627 - acc: 0.0772 - val_loss: 2.9741 - val_acc: 0.0843\n",
      "Epoch 124/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9623 - acc: 0.0787 - val_loss: 2.9738 - val_acc: 0.0843\n",
      "Epoch 125/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9620 - acc: 0.0787 - val_loss: 2.9736 - val_acc: 0.0843\n",
      "Epoch 126/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9616 - acc: 0.0787 - val_loss: 2.9733 - val_acc: 0.0843\n",
      "Epoch 127/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9612 - acc: 0.0801 - val_loss: 2.9731 - val_acc: 0.0843\n",
      "Epoch 128/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9609 - acc: 0.0815 - val_loss: 2.9729 - val_acc: 0.0843\n",
      "Epoch 129/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9605 - acc: 0.0815 - val_loss: 2.9727 - val_acc: 0.0843\n",
      "Epoch 130/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9602 - acc: 0.0829 - val_loss: 2.9725 - val_acc: 0.0843\n",
      "Epoch 131/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9599 - acc: 0.0829 - val_loss: 2.9722 - val_acc: 0.0843\n",
      "Epoch 132/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9595 - acc: 0.0815 - val_loss: 2.9720 - val_acc: 0.0843\n",
      "Epoch 133/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9592 - acc: 0.0815 - val_loss: 2.9718 - val_acc: 0.0899\n",
      "Epoch 134/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9589 - acc: 0.0815 - val_loss: 2.9716 - val_acc: 0.0899\n",
      "Epoch 135/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9585 - acc: 0.0815 - val_loss: 2.9714 - val_acc: 0.0899\n",
      "Epoch 136/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9582 - acc: 0.0815 - val_loss: 2.9712 - val_acc: 0.0899\n",
      "Epoch 137/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9579 - acc: 0.0815 - val_loss: 2.9710 - val_acc: 0.0899\n",
      "Epoch 138/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9576 - acc: 0.0815 - val_loss: 2.9708 - val_acc: 0.0899\n",
      "Epoch 139/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9573 - acc: 0.0829 - val_loss: 2.9706 - val_acc: 0.0899\n",
      "Epoch 140/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9570 - acc: 0.0843 - val_loss: 2.9705 - val_acc: 0.0899\n",
      "Epoch 141/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9567 - acc: 0.0829 - val_loss: 2.9703 - val_acc: 0.0899\n",
      "Epoch 142/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9565 - acc: 0.0843 - val_loss: 2.9701 - val_acc: 0.0899\n",
      "Epoch 143/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9562 - acc: 0.0843 - val_loss: 2.9699 - val_acc: 0.0899\n",
      "Epoch 144/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9559 - acc: 0.0857 - val_loss: 2.9697 - val_acc: 0.0899\n",
      "Epoch 145/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9556 - acc: 0.0843 - val_loss: 2.9696 - val_acc: 0.0899\n",
      "Epoch 146/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9554 - acc: 0.0829 - val_loss: 2.9694 - val_acc: 0.0955\n",
      "Epoch 147/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9551 - acc: 0.0829 - val_loss: 2.9692 - val_acc: 0.0955\n",
      "Epoch 148/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9549 - acc: 0.0829 - val_loss: 2.9691 - val_acc: 0.0955\n",
      "Epoch 149/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9547 - acc: 0.0843 - val_loss: 2.9689 - val_acc: 0.0955\n",
      "Epoch 150/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9544 - acc: 0.0843 - val_loss: 2.9687 - val_acc: 0.0955\n",
      "Epoch 151/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9542 - acc: 0.0843 - val_loss: 2.9686 - val_acc: 0.0955\n",
      "Epoch 152/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9539 - acc: 0.0857 - val_loss: 2.9685 - val_acc: 0.0955\n",
      "Epoch 153/600\n",
      "712/712 [==============================] - 0s 69us/sample - loss: 2.9537 - acc: 0.0857 - val_loss: 2.9683 - val_acc: 0.0955\n",
      "Epoch 154/600\n",
      "712/712 [==============================] - 0s 58us/sample - loss: 2.9535 - acc: 0.0885 - val_loss: 2.9682 - val_acc: 0.0955\n",
      "Epoch 155/600\n",
      "712/712 [==============================] - 0s 58us/sample - loss: 2.9533 - acc: 0.0913 - val_loss: 2.9680 - val_acc: 0.0955\n",
      "Epoch 156/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9531 - acc: 0.0913 - val_loss: 2.9679 - val_acc: 0.0955\n",
      "Epoch 157/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9529 - acc: 0.0885 - val_loss: 2.9678 - val_acc: 0.0955\n",
      "Epoch 158/600\n",
      "712/712 [==============================] - 0s 135us/sample - loss: 2.9527 - acc: 0.0899 - val_loss: 2.9676 - val_acc: 0.0955\n",
      "Epoch 159/600\n",
      "712/712 [==============================] - 0s 70us/sample - loss: 2.9525 - acc: 0.0899 - val_loss: 2.9675 - val_acc: 0.0955\n",
      "Epoch 160/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9522 - acc: 0.0899 - val_loss: 2.9673 - val_acc: 0.0955\n",
      "Epoch 161/600\n",
      "712/712 [==============================] - 0s 69us/sample - loss: 2.9521 - acc: 0.0899 - val_loss: 2.9672 - val_acc: 0.0955\n",
      "Epoch 162/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9518 - acc: 0.0899 - val_loss: 2.9670 - val_acc: 0.0955\n",
      "Epoch 163/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9516 - acc: 0.0899 - val_loss: 2.9669 - val_acc: 0.1011\n",
      "Epoch 164/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9514 - acc: 0.0899 - val_loss: 2.9667 - val_acc: 0.1011\n",
      "Epoch 165/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9512 - acc: 0.0899 - val_loss: 2.9666 - val_acc: 0.1011\n",
      "Epoch 166/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9510 - acc: 0.0885 - val_loss: 2.9664 - val_acc: 0.1011\n",
      "Epoch 167/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9509 - acc: 0.0885 - val_loss: 2.9663 - val_acc: 0.1011\n",
      "Epoch 168/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9507 - acc: 0.0885 - val_loss: 2.9661 - val_acc: 0.1011\n",
      "Epoch 169/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9505 - acc: 0.0885 - val_loss: 2.9660 - val_acc: 0.1011\n",
      "Epoch 170/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9503 - acc: 0.0885 - val_loss: 2.9658 - val_acc: 0.1067\n",
      "Epoch 171/600\n",
      "712/712 [==============================] - 0s 106us/sample - loss: 2.9501 - acc: 0.0885 - val_loss: 2.9657 - val_acc: 0.1067\n",
      "Epoch 172/600\n",
      "712/712 [==============================] - 0s 75us/sample - loss: 2.9500 - acc: 0.0885 - val_loss: 2.9656 - val_acc: 0.1067\n",
      "Epoch 173/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9498 - acc: 0.0885 - val_loss: 2.9655 - val_acc: 0.1067\n",
      "Epoch 174/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9497 - acc: 0.0885 - val_loss: 2.9653 - val_acc: 0.1067\n",
      "Epoch 175/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9495 - acc: 0.0885 - val_loss: 2.9652 - val_acc: 0.1067\n",
      "Epoch 176/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9493 - acc: 0.0885 - val_loss: 2.9650 - val_acc: 0.1067\n",
      "Epoch 177/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9492 - acc: 0.0885 - val_loss: 2.9649 - val_acc: 0.1124\n",
      "Epoch 178/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9490 - acc: 0.0871 - val_loss: 2.9647 - val_acc: 0.1124\n",
      "Epoch 179/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9489 - acc: 0.0871 - val_loss: 2.9646 - val_acc: 0.1124\n",
      "Epoch 180/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9487 - acc: 0.0871 - val_loss: 2.9644 - val_acc: 0.1124\n",
      "Epoch 181/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9486 - acc: 0.0871 - val_loss: 2.9643 - val_acc: 0.1124\n",
      "Epoch 182/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9485 - acc: 0.0871 - val_loss: 2.9641 - val_acc: 0.1124\n",
      "Epoch 183/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9483 - acc: 0.0871 - val_loss: 2.9640 - val_acc: 0.1124\n",
      "Epoch 184/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9482 - acc: 0.0857 - val_loss: 2.9639 - val_acc: 0.1124\n",
      "Epoch 185/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9481 - acc: 0.0843 - val_loss: 2.9637 - val_acc: 0.1124\n",
      "Epoch 186/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9480 - acc: 0.0843 - val_loss: 2.9636 - val_acc: 0.1180\n",
      "Epoch 187/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9479 - acc: 0.0843 - val_loss: 2.9635 - val_acc: 0.1180\n",
      "Epoch 188/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9478 - acc: 0.0843 - val_loss: 2.9634 - val_acc: 0.1180\n",
      "Epoch 189/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9476 - acc: 0.0843 - val_loss: 2.9632 - val_acc: 0.1180\n",
      "Epoch 190/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9475 - acc: 0.0843 - val_loss: 2.9631 - val_acc: 0.1180\n",
      "Epoch 191/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9474 - acc: 0.0829 - val_loss: 2.9629 - val_acc: 0.1180\n",
      "Epoch 192/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9473 - acc: 0.0829 - val_loss: 2.9628 - val_acc: 0.1180\n",
      "Epoch 193/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9472 - acc: 0.0829 - val_loss: 2.9627 - val_acc: 0.1180\n",
      "Epoch 194/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9471 - acc: 0.0829 - val_loss: 2.9625 - val_acc: 0.1180\n",
      "Epoch 195/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9470 - acc: 0.0829 - val_loss: 2.9624 - val_acc: 0.1180\n",
      "Epoch 196/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9469 - acc: 0.0829 - val_loss: 2.9623 - val_acc: 0.1180\n",
      "Epoch 197/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9468 - acc: 0.0829 - val_loss: 2.9622 - val_acc: 0.1180\n",
      "Epoch 198/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9467 - acc: 0.0829 - val_loss: 2.9621 - val_acc: 0.1180\n",
      "Epoch 199/600\n",
      "712/712 [==============================] - 0s 69us/sample - loss: 2.9466 - acc: 0.0829 - val_loss: 2.9619 - val_acc: 0.1180\n",
      "Epoch 200/600\n",
      "712/712 [==============================] - 0s 68us/sample - loss: 2.9465 - acc: 0.0829 - val_loss: 2.9618 - val_acc: 0.1180\n",
      "Epoch 201/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9464 - acc: 0.0829 - val_loss: 2.9617 - val_acc: 0.1180\n",
      "Epoch 202/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9463 - acc: 0.0829 - val_loss: 2.9616 - val_acc: 0.1180\n",
      "Epoch 203/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9462 - acc: 0.0843 - val_loss: 2.9614 - val_acc: 0.1180\n",
      "Epoch 204/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9461 - acc: 0.0843 - val_loss: 2.9613 - val_acc: 0.1180\n",
      "Epoch 205/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9460 - acc: 0.0829 - val_loss: 2.9612 - val_acc: 0.1180\n",
      "Epoch 206/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9459 - acc: 0.0829 - val_loss: 2.9610 - val_acc: 0.1180\n",
      "Epoch 207/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9458 - acc: 0.0829 - val_loss: 2.9609 - val_acc: 0.1180\n",
      "Epoch 208/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9457 - acc: 0.0829 - val_loss: 2.9608 - val_acc: 0.1180\n",
      "Epoch 209/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9456 - acc: 0.0829 - val_loss: 2.9607 - val_acc: 0.1180\n",
      "Epoch 210/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9455 - acc: 0.0829 - val_loss: 2.9606 - val_acc: 0.1180\n",
      "Epoch 211/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9454 - acc: 0.0843 - val_loss: 2.9604 - val_acc: 0.1180\n",
      "Epoch 212/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9453 - acc: 0.0843 - val_loss: 2.9603 - val_acc: 0.1180\n",
      "Epoch 213/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9452 - acc: 0.0843 - val_loss: 2.9601 - val_acc: 0.1180\n",
      "Epoch 214/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9451 - acc: 0.0843 - val_loss: 2.9600 - val_acc: 0.1180\n",
      "Epoch 215/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9450 - acc: 0.0843 - val_loss: 2.9599 - val_acc: 0.1180\n",
      "Epoch 216/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9450 - acc: 0.0843 - val_loss: 2.9598 - val_acc: 0.1180\n",
      "Epoch 217/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9449 - acc: 0.0871 - val_loss: 2.9597 - val_acc: 0.1180\n",
      "Epoch 218/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9448 - acc: 0.0871 - val_loss: 2.9596 - val_acc: 0.1180\n",
      "Epoch 219/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9447 - acc: 0.0885 - val_loss: 2.9594 - val_acc: 0.1180\n",
      "Epoch 220/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9446 - acc: 0.0885 - val_loss: 2.9593 - val_acc: 0.1180\n",
      "Epoch 221/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9445 - acc: 0.0885 - val_loss: 2.9592 - val_acc: 0.1180\n",
      "Epoch 222/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9444 - acc: 0.0899 - val_loss: 2.9591 - val_acc: 0.1180\n",
      "Epoch 223/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9443 - acc: 0.0899 - val_loss: 2.9590 - val_acc: 0.1180\n",
      "Epoch 224/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9442 - acc: 0.0899 - val_loss: 2.9588 - val_acc: 0.1236\n",
      "Epoch 225/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9441 - acc: 0.0899 - val_loss: 2.9587 - val_acc: 0.1292\n",
      "Epoch 226/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9441 - acc: 0.0899 - val_loss: 2.9586 - val_acc: 0.1292\n",
      "Epoch 227/600\n",
      "712/712 [==============================] - 0s 68us/sample - loss: 2.9440 - acc: 0.0899 - val_loss: 2.9585 - val_acc: 0.1292\n",
      "Epoch 228/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9439 - acc: 0.0899 - val_loss: 2.9584 - val_acc: 0.1292\n",
      "Epoch 229/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9438 - acc: 0.0899 - val_loss: 2.9583 - val_acc: 0.1292\n",
      "Epoch 230/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9438 - acc: 0.0899 - val_loss: 2.9582 - val_acc: 0.1292\n",
      "Epoch 231/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9437 - acc: 0.0899 - val_loss: 2.9581 - val_acc: 0.1292\n",
      "Epoch 232/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9436 - acc: 0.0899 - val_loss: 2.9580 - val_acc: 0.1292\n",
      "Epoch 233/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9435 - acc: 0.0913 - val_loss: 2.9578 - val_acc: 0.1292\n",
      "Epoch 234/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9435 - acc: 0.0913 - val_loss: 2.9577 - val_acc: 0.1292\n",
      "Epoch 235/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9434 - acc: 0.0913 - val_loss: 2.9576 - val_acc: 0.1292\n",
      "Epoch 236/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9433 - acc: 0.0913 - val_loss: 2.9575 - val_acc: 0.1236\n",
      "Epoch 237/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9433 - acc: 0.0927 - val_loss: 2.9574 - val_acc: 0.1236\n",
      "Epoch 238/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9432 - acc: 0.0927 - val_loss: 2.9573 - val_acc: 0.1236\n",
      "Epoch 239/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9431 - acc: 0.0927 - val_loss: 2.9572 - val_acc: 0.1236\n",
      "Epoch 240/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9431 - acc: 0.0941 - val_loss: 2.9570 - val_acc: 0.1236\n",
      "Epoch 241/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9430 - acc: 0.0941 - val_loss: 2.9569 - val_acc: 0.1236\n",
      "Epoch 242/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9429 - acc: 0.0941 - val_loss: 2.9568 - val_acc: 0.1236\n",
      "Epoch 243/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9429 - acc: 0.0927 - val_loss: 2.9567 - val_acc: 0.1236\n",
      "Epoch 244/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9428 - acc: 0.0927 - val_loss: 2.9565 - val_acc: 0.1236\n",
      "Epoch 245/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9427 - acc: 0.0927 - val_loss: 2.9564 - val_acc: 0.1236\n",
      "Epoch 246/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9427 - acc: 0.0927 - val_loss: 2.9563 - val_acc: 0.1236\n",
      "Epoch 247/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9426 - acc: 0.0927 - val_loss: 2.9562 - val_acc: 0.1236\n",
      "Epoch 248/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9426 - acc: 0.0927 - val_loss: 2.9561 - val_acc: 0.1236\n",
      "Epoch 249/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9425 - acc: 0.0941 - val_loss: 2.9560 - val_acc: 0.1236\n",
      "Epoch 250/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9424 - acc: 0.0927 - val_loss: 2.9559 - val_acc: 0.1236\n",
      "Epoch 251/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9424 - acc: 0.0941 - val_loss: 2.9558 - val_acc: 0.1236\n",
      "Epoch 252/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9423 - acc: 0.0941 - val_loss: 2.9557 - val_acc: 0.1236\n",
      "Epoch 253/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9423 - acc: 0.0941 - val_loss: 2.9556 - val_acc: 0.1236\n",
      "Epoch 254/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9422 - acc: 0.0941 - val_loss: 2.9554 - val_acc: 0.1236\n",
      "Epoch 255/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9422 - acc: 0.0941 - val_loss: 2.9553 - val_acc: 0.1236\n",
      "Epoch 256/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9421 - acc: 0.0941 - val_loss: 2.9552 - val_acc: 0.1236\n",
      "Epoch 257/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9420 - acc: 0.0941 - val_loss: 2.9551 - val_acc: 0.1236\n",
      "Epoch 258/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9420 - acc: 0.0941 - val_loss: 2.9550 - val_acc: 0.1292\n",
      "Epoch 259/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9419 - acc: 0.0941 - val_loss: 2.9549 - val_acc: 0.1292\n",
      "Epoch 260/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9419 - acc: 0.0941 - val_loss: 2.9548 - val_acc: 0.1292\n",
      "Epoch 261/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9418 - acc: 0.0941 - val_loss: 2.9547 - val_acc: 0.1292\n",
      "Epoch 262/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9418 - acc: 0.0941 - val_loss: 2.9546 - val_acc: 0.1292\n",
      "Epoch 263/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9417 - acc: 0.0941 - val_loss: 2.9545 - val_acc: 0.1292\n",
      "Epoch 264/600\n",
      "712/712 [==============================] - 0s 59us/sample - loss: 2.9417 - acc: 0.0927 - val_loss: 2.9544 - val_acc: 0.1292\n",
      "Epoch 265/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9416 - acc: 0.0941 - val_loss: 2.9543 - val_acc: 0.1292\n",
      "Epoch 266/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9416 - acc: 0.0955 - val_loss: 2.9542 - val_acc: 0.1292\n",
      "Epoch 267/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9415 - acc: 0.0941 - val_loss: 2.9541 - val_acc: 0.1292\n",
      "Epoch 268/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9415 - acc: 0.0969 - val_loss: 2.9540 - val_acc: 0.1292\n",
      "Epoch 269/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9414 - acc: 0.0969 - val_loss: 2.9539 - val_acc: 0.1292\n",
      "Epoch 270/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9413 - acc: 0.0969 - val_loss: 2.9537 - val_acc: 0.1292\n",
      "Epoch 271/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9413 - acc: 0.0969 - val_loss: 2.9537 - val_acc: 0.1292\n",
      "Epoch 272/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9412 - acc: 0.0969 - val_loss: 2.9535 - val_acc: 0.1292\n",
      "Epoch 273/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9412 - acc: 0.0969 - val_loss: 2.9535 - val_acc: 0.1292\n",
      "Epoch 274/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9411 - acc: 0.0955 - val_loss: 2.9533 - val_acc: 0.1292\n",
      "Epoch 275/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9411 - acc: 0.0955 - val_loss: 2.9532 - val_acc: 0.1292\n",
      "Epoch 276/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9410 - acc: 0.0955 - val_loss: 2.9531 - val_acc: 0.1292\n",
      "Epoch 277/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9409 - acc: 0.0955 - val_loss: 2.9530 - val_acc: 0.1292\n",
      "Epoch 278/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9409 - acc: 0.0955 - val_loss: 2.9529 - val_acc: 0.1292\n",
      "Epoch 279/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9408 - acc: 0.0941 - val_loss: 2.9528 - val_acc: 0.1292\n",
      "Epoch 280/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9408 - acc: 0.0941 - val_loss: 2.9527 - val_acc: 0.1292\n",
      "Epoch 281/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9407 - acc: 0.0941 - val_loss: 2.9526 - val_acc: 0.1292\n",
      "Epoch 282/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9407 - acc: 0.0941 - val_loss: 2.9525 - val_acc: 0.1292\n",
      "Epoch 283/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9406 - acc: 0.0941 - val_loss: 2.9524 - val_acc: 0.1292\n",
      "Epoch 284/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9405 - acc: 0.0955 - val_loss: 2.9523 - val_acc: 0.1292\n",
      "Epoch 285/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9405 - acc: 0.0955 - val_loss: 2.9521 - val_acc: 0.1292\n",
      "Epoch 286/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9404 - acc: 0.0955 - val_loss: 2.9521 - val_acc: 0.1292\n",
      "Epoch 287/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9404 - acc: 0.0955 - val_loss: 2.9520 - val_acc: 0.1292\n",
      "Epoch 288/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9403 - acc: 0.0955 - val_loss: 2.9518 - val_acc: 0.1292\n",
      "Epoch 289/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9402 - acc: 0.0955 - val_loss: 2.9517 - val_acc: 0.1292\n",
      "Epoch 290/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9402 - acc: 0.0955 - val_loss: 2.9516 - val_acc: 0.1292\n",
      "Epoch 291/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9401 - acc: 0.0941 - val_loss: 2.9515 - val_acc: 0.1292\n",
      "Epoch 292/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9401 - acc: 0.0941 - val_loss: 2.9514 - val_acc: 0.1292\n",
      "Epoch 293/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9400 - acc: 0.0955 - val_loss: 2.9513 - val_acc: 0.1292\n",
      "Epoch 294/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9400 - acc: 0.0955 - val_loss: 2.9512 - val_acc: 0.1292\n",
      "Epoch 295/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9399 - acc: 0.0955 - val_loss: 2.9512 - val_acc: 0.1292\n",
      "Epoch 296/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9399 - acc: 0.0955 - val_loss: 2.9511 - val_acc: 0.1292\n",
      "Epoch 297/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9398 - acc: 0.0955 - val_loss: 2.9510 - val_acc: 0.1292\n",
      "Epoch 298/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9398 - acc: 0.0955 - val_loss: 2.9509 - val_acc: 0.1292\n",
      "Epoch 299/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9397 - acc: 0.0955 - val_loss: 2.9508 - val_acc: 0.1292\n",
      "Epoch 300/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9397 - acc: 0.0955 - val_loss: 2.9507 - val_acc: 0.1292\n",
      "Epoch 301/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9396 - acc: 0.0941 - val_loss: 2.9506 - val_acc: 0.1292\n",
      "Epoch 302/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9396 - acc: 0.0941 - val_loss: 2.9505 - val_acc: 0.1292\n",
      "Epoch 303/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9395 - acc: 0.0941 - val_loss: 2.9504 - val_acc: 0.1292\n",
      "Epoch 304/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9395 - acc: 0.0941 - val_loss: 2.9503 - val_acc: 0.1292\n",
      "Epoch 305/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9394 - acc: 0.0941 - val_loss: 2.9502 - val_acc: 0.1292\n",
      "Epoch 306/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9394 - acc: 0.0941 - val_loss: 2.9501 - val_acc: 0.1292\n",
      "Epoch 307/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9393 - acc: 0.0941 - val_loss: 2.9500 - val_acc: 0.1292\n",
      "Epoch 308/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9393 - acc: 0.0941 - val_loss: 2.9500 - val_acc: 0.1292\n",
      "Epoch 309/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9392 - acc: 0.0941 - val_loss: 2.9499 - val_acc: 0.1292\n",
      "Epoch 310/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9392 - acc: 0.0941 - val_loss: 2.9498 - val_acc: 0.1292\n",
      "Epoch 311/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9392 - acc: 0.0941 - val_loss: 2.9497 - val_acc: 0.1292\n",
      "Epoch 312/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9391 - acc: 0.0941 - val_loss: 2.9496 - val_acc: 0.1292\n",
      "Epoch 313/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9391 - acc: 0.0941 - val_loss: 2.9495 - val_acc: 0.1292\n",
      "Epoch 314/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9390 - acc: 0.0941 - val_loss: 2.9494 - val_acc: 0.1292\n",
      "Epoch 315/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9390 - acc: 0.0941 - val_loss: 2.9493 - val_acc: 0.1292\n",
      "Epoch 316/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9389 - acc: 0.0941 - val_loss: 2.9492 - val_acc: 0.1292\n",
      "Epoch 317/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9389 - acc: 0.0941 - val_loss: 2.9491 - val_acc: 0.1292\n",
      "Epoch 318/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9388 - acc: 0.0941 - val_loss: 2.9490 - val_acc: 0.1292\n",
      "Epoch 319/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9388 - acc: 0.0941 - val_loss: 2.9490 - val_acc: 0.1292\n",
      "Epoch 320/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9387 - acc: 0.0955 - val_loss: 2.9489 - val_acc: 0.1292\n",
      "Epoch 321/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9387 - acc: 0.0955 - val_loss: 2.9488 - val_acc: 0.1292\n",
      "Epoch 322/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9387 - acc: 0.0955 - val_loss: 2.9487 - val_acc: 0.1292\n",
      "Epoch 323/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9386 - acc: 0.0955 - val_loss: 2.9486 - val_acc: 0.1292\n",
      "Epoch 324/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9386 - acc: 0.0955 - val_loss: 2.9485 - val_acc: 0.1292\n",
      "Epoch 325/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9385 - acc: 0.0955 - val_loss: 2.9484 - val_acc: 0.1292\n",
      "Epoch 326/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9385 - acc: 0.0955 - val_loss: 2.9483 - val_acc: 0.1292\n",
      "Epoch 327/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9384 - acc: 0.0955 - val_loss: 2.9482 - val_acc: 0.1292\n",
      "Epoch 328/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9384 - acc: 0.0955 - val_loss: 2.9481 - val_acc: 0.1292\n",
      "Epoch 329/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9384 - acc: 0.0955 - val_loss: 2.9480 - val_acc: 0.1292\n",
      "Epoch 330/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9383 - acc: 0.0955 - val_loss: 2.9480 - val_acc: 0.1292\n",
      "Epoch 331/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9383 - acc: 0.0955 - val_loss: 2.9478 - val_acc: 0.1292\n",
      "Epoch 332/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9382 - acc: 0.0955 - val_loss: 2.9477 - val_acc: 0.1292\n",
      "Epoch 333/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9382 - acc: 0.0955 - val_loss: 2.9477 - val_acc: 0.1292\n",
      "Epoch 334/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9381 - acc: 0.0955 - val_loss: 2.9475 - val_acc: 0.1292\n",
      "Epoch 335/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9381 - acc: 0.0955 - val_loss: 2.9475 - val_acc: 0.1292\n",
      "Epoch 336/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9380 - acc: 0.0955 - val_loss: 2.9474 - val_acc: 0.1292\n",
      "Epoch 337/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9380 - acc: 0.0941 - val_loss: 2.9473 - val_acc: 0.1292\n",
      "Epoch 338/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9379 - acc: 0.0941 - val_loss: 2.9472 - val_acc: 0.1292\n",
      "Epoch 339/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9379 - acc: 0.0941 - val_loss: 2.9471 - val_acc: 0.1292\n",
      "Epoch 340/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9379 - acc: 0.0941 - val_loss: 2.9470 - val_acc: 0.1292\n",
      "Epoch 341/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9378 - acc: 0.0941 - val_loss: 2.9469 - val_acc: 0.1292\n",
      "Epoch 342/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9378 - acc: 0.0955 - val_loss: 2.9468 - val_acc: 0.1348\n",
      "Epoch 343/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9377 - acc: 0.0955 - val_loss: 2.9468 - val_acc: 0.1348\n",
      "Epoch 344/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9377 - acc: 0.0955 - val_loss: 2.9467 - val_acc: 0.1348\n",
      "Epoch 345/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9376 - acc: 0.0955 - val_loss: 2.9466 - val_acc: 0.1348\n",
      "Epoch 346/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9376 - acc: 0.0955 - val_loss: 2.9465 - val_acc: 0.1348\n",
      "Epoch 347/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9375 - acc: 0.0955 - val_loss: 2.9464 - val_acc: 0.1292\n",
      "Epoch 348/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9375 - acc: 0.0955 - val_loss: 2.9463 - val_acc: 0.1292\n",
      "Epoch 349/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9375 - acc: 0.0955 - val_loss: 2.9462 - val_acc: 0.1292\n",
      "Epoch 350/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9374 - acc: 0.0955 - val_loss: 2.9461 - val_acc: 0.1292\n",
      "Epoch 351/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9374 - acc: 0.0955 - val_loss: 2.9460 - val_acc: 0.1292\n",
      "Epoch 352/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9373 - acc: 0.0955 - val_loss: 2.9459 - val_acc: 0.1292\n",
      "Epoch 353/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9373 - acc: 0.0955 - val_loss: 2.9458 - val_acc: 0.1292\n",
      "Epoch 354/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9372 - acc: 0.0955 - val_loss: 2.9457 - val_acc: 0.1292\n",
      "Epoch 355/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9372 - acc: 0.0941 - val_loss: 2.9457 - val_acc: 0.1292\n",
      "Epoch 356/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9371 - acc: 0.0955 - val_loss: 2.9456 - val_acc: 0.1348\n",
      "Epoch 357/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9371 - acc: 0.0955 - val_loss: 2.9454 - val_acc: 0.1348\n",
      "Epoch 358/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9370 - acc: 0.0955 - val_loss: 2.9453 - val_acc: 0.1348\n",
      "Epoch 359/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9370 - acc: 0.0955 - val_loss: 2.9453 - val_acc: 0.1348\n",
      "Epoch 360/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9370 - acc: 0.0955 - val_loss: 2.9452 - val_acc: 0.1292\n",
      "Epoch 361/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9369 - acc: 0.0941 - val_loss: 2.9451 - val_acc: 0.1292\n",
      "Epoch 362/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9369 - acc: 0.0955 - val_loss: 2.9450 - val_acc: 0.1292\n",
      "Epoch 363/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9368 - acc: 0.0941 - val_loss: 2.9449 - val_acc: 0.1292\n",
      "Epoch 364/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9368 - acc: 0.0941 - val_loss: 2.9448 - val_acc: 0.1292\n",
      "Epoch 365/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9368 - acc: 0.0941 - val_loss: 2.9447 - val_acc: 0.1292\n",
      "Epoch 366/600\n",
      "712/712 [==============================] - 0s 72us/sample - loss: 2.9367 - acc: 0.0927 - val_loss: 2.9446 - val_acc: 0.1292\n",
      "Epoch 367/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9367 - acc: 0.0927 - val_loss: 2.9445 - val_acc: 0.1292\n",
      "Epoch 368/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9366 - acc: 0.0927 - val_loss: 2.9444 - val_acc: 0.1292\n",
      "Epoch 369/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9366 - acc: 0.0927 - val_loss: 2.9443 - val_acc: 0.1292\n",
      "Epoch 370/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9365 - acc: 0.0913 - val_loss: 2.9442 - val_acc: 0.1292\n",
      "Epoch 371/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9365 - acc: 0.0913 - val_loss: 2.9441 - val_acc: 0.1292\n",
      "Epoch 372/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9365 - acc: 0.0913 - val_loss: 2.9441 - val_acc: 0.1292\n",
      "Epoch 373/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9364 - acc: 0.0913 - val_loss: 2.9440 - val_acc: 0.1292\n",
      "Epoch 374/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9364 - acc: 0.0913 - val_loss: 2.9439 - val_acc: 0.1292\n",
      "Epoch 375/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9364 - acc: 0.0913 - val_loss: 2.9439 - val_acc: 0.1348\n",
      "Epoch 376/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9363 - acc: 0.0899 - val_loss: 2.9437 - val_acc: 0.1348\n",
      "Epoch 377/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9363 - acc: 0.0899 - val_loss: 2.9436 - val_acc: 0.1348\n",
      "Epoch 378/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9362 - acc: 0.0899 - val_loss: 2.9436 - val_acc: 0.1348\n",
      "Epoch 379/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9362 - acc: 0.0899 - val_loss: 2.9435 - val_acc: 0.1348\n",
      "Epoch 380/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9362 - acc: 0.0899 - val_loss: 2.9434 - val_acc: 0.1348\n",
      "Epoch 381/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9361 - acc: 0.0899 - val_loss: 2.9433 - val_acc: 0.1348\n",
      "Epoch 382/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9361 - acc: 0.0899 - val_loss: 2.9432 - val_acc: 0.1348\n",
      "Epoch 383/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9361 - acc: 0.0899 - val_loss: 2.9432 - val_acc: 0.1348\n",
      "Epoch 384/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9360 - acc: 0.0899 - val_loss: 2.9431 - val_acc: 0.1348\n",
      "Epoch 385/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9360 - acc: 0.0899 - val_loss: 2.9430 - val_acc: 0.1348\n",
      "Epoch 386/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9360 - acc: 0.0899 - val_loss: 2.9429 - val_acc: 0.1348\n",
      "Epoch 387/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9359 - acc: 0.0899 - val_loss: 2.9428 - val_acc: 0.1348\n",
      "Epoch 388/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9359 - acc: 0.0899 - val_loss: 2.9428 - val_acc: 0.1348\n",
      "Epoch 389/600\n",
      "712/712 [==============================] - 0s 59us/sample - loss: 2.9359 - acc: 0.0899 - val_loss: 2.9427 - val_acc: 0.1348\n",
      "Epoch 390/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9358 - acc: 0.0899 - val_loss: 2.9426 - val_acc: 0.1348\n",
      "Epoch 391/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9358 - acc: 0.0899 - val_loss: 2.9425 - val_acc: 0.1348\n",
      "Epoch 392/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9358 - acc: 0.0899 - val_loss: 2.9425 - val_acc: 0.1348\n",
      "Epoch 393/600\n",
      "712/712 [==============================] - 0s 83us/sample - loss: 2.9357 - acc: 0.0899 - val_loss: 2.9424 - val_acc: 0.1348\n",
      "Epoch 394/600\n",
      "712/712 [==============================] - 0s 71us/sample - loss: 2.9357 - acc: 0.0899 - val_loss: 2.9423 - val_acc: 0.1348\n",
      "Epoch 395/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9357 - acc: 0.0899 - val_loss: 2.9422 - val_acc: 0.1348\n",
      "Epoch 396/600\n",
      "712/712 [==============================] - 0s 68us/sample - loss: 2.9356 - acc: 0.0913 - val_loss: 2.9422 - val_acc: 0.1348\n",
      "Epoch 397/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9356 - acc: 0.0913 - val_loss: 2.9421 - val_acc: 0.1348\n",
      "Epoch 398/600\n",
      "712/712 [==============================] - 0s 71us/sample - loss: 2.9356 - acc: 0.0927 - val_loss: 2.9420 - val_acc: 0.1348\n",
      "Epoch 399/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9355 - acc: 0.0927 - val_loss: 2.9419 - val_acc: 0.1348\n",
      "Epoch 400/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9355 - acc: 0.0927 - val_loss: 2.9418 - val_acc: 0.1348\n",
      "Epoch 401/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9354 - acc: 0.0913 - val_loss: 2.9418 - val_acc: 0.1348\n",
      "Epoch 402/600\n",
      "712/712 [==============================] - 0s 87us/sample - loss: 2.9354 - acc: 0.0927 - val_loss: 2.9417 - val_acc: 0.1348\n",
      "Epoch 403/600\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 2.9354 - acc: 0.0913 - val_loss: 2.9416 - val_acc: 0.1348\n",
      "Epoch 404/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9353 - acc: 0.0913 - val_loss: 2.9416 - val_acc: 0.1348\n",
      "Epoch 405/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9353 - acc: 0.0899 - val_loss: 2.9415 - val_acc: 0.1292\n",
      "Epoch 406/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9352 - acc: 0.0899 - val_loss: 2.9414 - val_acc: 0.1292\n",
      "Epoch 407/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9352 - acc: 0.0913 - val_loss: 2.9413 - val_acc: 0.1292\n",
      "Epoch 408/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9352 - acc: 0.0913 - val_loss: 2.9412 - val_acc: 0.1292\n",
      "Epoch 409/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9351 - acc: 0.0913 - val_loss: 2.9411 - val_acc: 0.1292\n",
      "Epoch 410/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9351 - acc: 0.0927 - val_loss: 2.9410 - val_acc: 0.1292\n",
      "Epoch 411/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9350 - acc: 0.0913 - val_loss: 2.9410 - val_acc: 0.1292\n",
      "Epoch 412/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9350 - acc: 0.0913 - val_loss: 2.9409 - val_acc: 0.1292\n",
      "Epoch 413/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9350 - acc: 0.0927 - val_loss: 2.9408 - val_acc: 0.1292\n",
      "Epoch 414/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9349 - acc: 0.0927 - val_loss: 2.9408 - val_acc: 0.1292\n",
      "Epoch 415/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9349 - acc: 0.0927 - val_loss: 2.9407 - val_acc: 0.1292\n",
      "Epoch 416/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9349 - acc: 0.0927 - val_loss: 2.9406 - val_acc: 0.1292\n",
      "Epoch 417/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9348 - acc: 0.0927 - val_loss: 2.9406 - val_acc: 0.1292\n",
      "Epoch 418/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9348 - acc: 0.0927 - val_loss: 2.9405 - val_acc: 0.1292\n",
      "Epoch 419/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9347 - acc: 0.0927 - val_loss: 2.9404 - val_acc: 0.1292\n",
      "Epoch 420/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9347 - acc: 0.0927 - val_loss: 2.9404 - val_acc: 0.1292\n",
      "Epoch 421/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9347 - acc: 0.0927 - val_loss: 2.9403 - val_acc: 0.1292\n",
      "Epoch 422/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9346 - acc: 0.0913 - val_loss: 2.9402 - val_acc: 0.1292\n",
      "Epoch 423/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9346 - acc: 0.0913 - val_loss: 2.9402 - val_acc: 0.1292\n",
      "Epoch 424/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9346 - acc: 0.0913 - val_loss: 2.9401 - val_acc: 0.1292\n",
      "Epoch 425/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9345 - acc: 0.0913 - val_loss: 2.9400 - val_acc: 0.1292\n",
      "Epoch 426/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9345 - acc: 0.0899 - val_loss: 2.9400 - val_acc: 0.1292\n",
      "Epoch 427/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9345 - acc: 0.0899 - val_loss: 2.9399 - val_acc: 0.1292\n",
      "Epoch 428/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9344 - acc: 0.0899 - val_loss: 2.9398 - val_acc: 0.1292\n",
      "Epoch 429/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9344 - acc: 0.0899 - val_loss: 2.9397 - val_acc: 0.1292\n",
      "Epoch 430/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9344 - acc: 0.0899 - val_loss: 2.9397 - val_acc: 0.1292\n",
      "Epoch 431/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9343 - acc: 0.0899 - val_loss: 2.9396 - val_acc: 0.1292\n",
      "Epoch 432/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9343 - acc: 0.0899 - val_loss: 2.9395 - val_acc: 0.1292\n",
      "Epoch 433/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9343 - acc: 0.0899 - val_loss: 2.9395 - val_acc: 0.1292\n",
      "Epoch 434/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9342 - acc: 0.0899 - val_loss: 2.9394 - val_acc: 0.1292\n",
      "Epoch 435/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9342 - acc: 0.0913 - val_loss: 2.9394 - val_acc: 0.1292\n",
      "Epoch 436/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9342 - acc: 0.0913 - val_loss: 2.9393 - val_acc: 0.1292\n",
      "Epoch 437/600\n",
      "712/712 [==============================] - 0s 71us/sample - loss: 2.9342 - acc: 0.0913 - val_loss: 2.9393 - val_acc: 0.1292\n",
      "Epoch 438/600\n",
      "712/712 [==============================] - 0s 81us/sample - loss: 2.9341 - acc: 0.0913 - val_loss: 2.9392 - val_acc: 0.1236\n",
      "Epoch 439/600\n",
      "712/712 [==============================] - 0s 70us/sample - loss: 2.9341 - acc: 0.0899 - val_loss: 2.9391 - val_acc: 0.1236\n",
      "Epoch 440/600\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 2.9341 - acc: 0.0899 - val_loss: 2.9391 - val_acc: 0.1236\n",
      "Epoch 441/600\n",
      "712/712 [==============================] - 0s 75us/sample - loss: 2.9340 - acc: 0.0899 - val_loss: 2.9390 - val_acc: 0.1180\n",
      "Epoch 442/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9340 - acc: 0.0899 - val_loss: 2.9390 - val_acc: 0.1180\n",
      "Epoch 443/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9340 - acc: 0.0899 - val_loss: 2.9389 - val_acc: 0.1180\n",
      "Epoch 444/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9339 - acc: 0.0899 - val_loss: 2.9388 - val_acc: 0.1180\n",
      "Epoch 445/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9339 - acc: 0.0899 - val_loss: 2.9388 - val_acc: 0.1180\n",
      "Epoch 446/600\n",
      "712/712 [==============================] - 0s 72us/sample - loss: 2.9339 - acc: 0.0899 - val_loss: 2.9387 - val_acc: 0.1180\n",
      "Epoch 447/600\n",
      "712/712 [==============================] - 0s 82us/sample - loss: 2.9338 - acc: 0.0899 - val_loss: 2.9386 - val_acc: 0.1180\n",
      "Epoch 448/600\n",
      "712/712 [==============================] - 0s 89us/sample - loss: 2.9338 - acc: 0.0885 - val_loss: 2.9385 - val_acc: 0.1180\n",
      "Epoch 449/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9338 - acc: 0.0885 - val_loss: 2.9385 - val_acc: 0.1180\n",
      "Epoch 450/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9337 - acc: 0.0885 - val_loss: 2.9384 - val_acc: 0.1180\n",
      "Epoch 451/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9337 - acc: 0.0885 - val_loss: 2.9384 - val_acc: 0.1180\n",
      "Epoch 452/600\n",
      "712/712 [==============================] - 0s 70us/sample - loss: 2.9337 - acc: 0.0885 - val_loss: 2.9383 - val_acc: 0.1180\n",
      "Epoch 453/600\n",
      "712/712 [==============================] - 0s 97us/sample - loss: 2.9337 - acc: 0.0885 - val_loss: 2.9383 - val_acc: 0.1180\n",
      "Epoch 454/600\n",
      "712/712 [==============================] - 0s 84us/sample - loss: 2.9336 - acc: 0.0885 - val_loss: 2.9382 - val_acc: 0.1180\n",
      "Epoch 455/600\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 2.9336 - acc: 0.0885 - val_loss: 2.9382 - val_acc: 0.1180\n",
      "Epoch 456/600\n",
      "712/712 [==============================] - 0s 74us/sample - loss: 2.9336 - acc: 0.0885 - val_loss: 2.9382 - val_acc: 0.1180\n",
      "Epoch 457/600\n",
      "712/712 [==============================] - 0s 76us/sample - loss: 2.9335 - acc: 0.0885 - val_loss: 2.9381 - val_acc: 0.1180\n",
      "Epoch 458/600\n",
      "712/712 [==============================] - 0s 76us/sample - loss: 2.9335 - acc: 0.0885 - val_loss: 2.9380 - val_acc: 0.1180\n",
      "Epoch 459/600\n",
      "712/712 [==============================] - 0s 76us/sample - loss: 2.9335 - acc: 0.0885 - val_loss: 2.9379 - val_acc: 0.1180\n",
      "Epoch 460/600\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 2.9334 - acc: 0.0885 - val_loss: 2.9379 - val_acc: 0.1180\n",
      "Epoch 461/600\n",
      "712/712 [==============================] - 0s 74us/sample - loss: 2.9334 - acc: 0.0885 - val_loss: 2.9378 - val_acc: 0.1180\n",
      "Epoch 462/600\n",
      "712/712 [==============================] - 0s 72us/sample - loss: 2.9334 - acc: 0.0885 - val_loss: 2.9378 - val_acc: 0.1180\n",
      "Epoch 463/600\n",
      "712/712 [==============================] - 0s 70us/sample - loss: 2.9334 - acc: 0.0885 - val_loss: 2.9377 - val_acc: 0.1180\n",
      "Epoch 464/600\n",
      "712/712 [==============================] - 0s 73us/sample - loss: 2.9333 - acc: 0.0885 - val_loss: 2.9377 - val_acc: 0.1180\n",
      "Epoch 465/600\n",
      "712/712 [==============================] - 0s 73us/sample - loss: 2.9333 - acc: 0.0913 - val_loss: 2.9376 - val_acc: 0.1180\n",
      "Epoch 466/600\n",
      "712/712 [==============================] - 0s 78us/sample - loss: 2.9333 - acc: 0.0899 - val_loss: 2.9376 - val_acc: 0.1180\n",
      "Epoch 467/600\n",
      "712/712 [==============================] - 0s 70us/sample - loss: 2.9332 - acc: 0.0899 - val_loss: 2.9375 - val_acc: 0.1180\n",
      "Epoch 468/600\n",
      "712/712 [==============================] - 0s 69us/sample - loss: 2.9332 - acc: 0.0913 - val_loss: 2.9375 - val_acc: 0.1180\n",
      "Epoch 469/600\n",
      "712/712 [==============================] - 0s 72us/sample - loss: 2.9332 - acc: 0.0913 - val_loss: 2.9374 - val_acc: 0.1180\n",
      "Epoch 470/600\n",
      "712/712 [==============================] - 0s 74us/sample - loss: 2.9332 - acc: 0.0913 - val_loss: 2.9374 - val_acc: 0.1180\n",
      "Epoch 471/600\n",
      "712/712 [==============================] - 0s 74us/sample - loss: 2.9331 - acc: 0.0913 - val_loss: 2.9373 - val_acc: 0.1180\n",
      "Epoch 472/600\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 2.9331 - acc: 0.0913 - val_loss: 2.9373 - val_acc: 0.1180\n",
      "Epoch 473/600\n",
      "712/712 [==============================] - 0s 88us/sample - loss: 2.9331 - acc: 0.0913 - val_loss: 2.9372 - val_acc: 0.1180\n",
      "Epoch 474/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 84us/sample - loss: 2.9331 - acc: 0.0913 - val_loss: 2.9372 - val_acc: 0.1180\n",
      "Epoch 475/600\n",
      "712/712 [==============================] - 0s 80us/sample - loss: 2.9330 - acc: 0.0913 - val_loss: 2.9371 - val_acc: 0.1180\n",
      "Epoch 476/600\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 2.9330 - acc: 0.0913 - val_loss: 2.9370 - val_acc: 0.1180\n",
      "Epoch 477/600\n",
      "712/712 [==============================] - 0s 75us/sample - loss: 2.9330 - acc: 0.0913 - val_loss: 2.9370 - val_acc: 0.1180\n",
      "Epoch 478/600\n",
      "712/712 [==============================] - 0s 70us/sample - loss: 2.9330 - acc: 0.0913 - val_loss: 2.9370 - val_acc: 0.1180\n",
      "Epoch 479/600\n",
      "712/712 [==============================] - 0s 73us/sample - loss: 2.9329 - acc: 0.0899 - val_loss: 2.9369 - val_acc: 0.1180\n",
      "Epoch 480/600\n",
      "712/712 [==============================] - 0s 71us/sample - loss: 2.9329 - acc: 0.0899 - val_loss: 2.9369 - val_acc: 0.1180\n",
      "Epoch 481/600\n",
      "712/712 [==============================] - 0s 70us/sample - loss: 2.9329 - acc: 0.0913 - val_loss: 2.9368 - val_acc: 0.1180\n",
      "Epoch 482/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9328 - acc: 0.0899 - val_loss: 2.9368 - val_acc: 0.1180\n",
      "Epoch 483/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9328 - acc: 0.0899 - val_loss: 2.9367 - val_acc: 0.1180\n",
      "Epoch 484/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9328 - acc: 0.0913 - val_loss: 2.9367 - val_acc: 0.1180\n",
      "Epoch 485/600\n",
      "712/712 [==============================] - 0s 69us/sample - loss: 2.9328 - acc: 0.0913 - val_loss: 2.9367 - val_acc: 0.1180\n",
      "Epoch 486/600\n",
      "712/712 [==============================] - 0s 69us/sample - loss: 2.9327 - acc: 0.0899 - val_loss: 2.9366 - val_acc: 0.1180\n",
      "Epoch 487/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9327 - acc: 0.0899 - val_loss: 2.9366 - val_acc: 0.1180\n",
      "Epoch 488/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9327 - acc: 0.0899 - val_loss: 2.9365 - val_acc: 0.1180\n",
      "Epoch 489/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9327 - acc: 0.0899 - val_loss: 2.9365 - val_acc: 0.1180\n",
      "Epoch 490/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9327 - acc: 0.0899 - val_loss: 2.9364 - val_acc: 0.1180\n",
      "Epoch 491/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9326 - acc: 0.0899 - val_loss: 2.9364 - val_acc: 0.1180\n",
      "Epoch 492/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9326 - acc: 0.0899 - val_loss: 2.9363 - val_acc: 0.1180\n",
      "Epoch 493/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9326 - acc: 0.0899 - val_loss: 2.9363 - val_acc: 0.1180\n",
      "Epoch 494/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9325 - acc: 0.0899 - val_loss: 2.9363 - val_acc: 0.1180\n",
      "Epoch 495/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9325 - acc: 0.0899 - val_loss: 2.9362 - val_acc: 0.1180\n",
      "Epoch 496/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9325 - acc: 0.0899 - val_loss: 2.9362 - val_acc: 0.1180\n",
      "Epoch 497/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9325 - acc: 0.0899 - val_loss: 2.9361 - val_acc: 0.1180\n",
      "Epoch 498/600\n",
      "712/712 [==============================] - 0s 69us/sample - loss: 2.9325 - acc: 0.0899 - val_loss: 2.9361 - val_acc: 0.1180\n",
      "Epoch 499/600\n",
      "712/712 [==============================] - 0s 79us/sample - loss: 2.9324 - acc: 0.0899 - val_loss: 2.9360 - val_acc: 0.1180\n",
      "Epoch 500/600\n",
      "712/712 [==============================] - 0s 72us/sample - loss: 2.9324 - acc: 0.0899 - val_loss: 2.9360 - val_acc: 0.1180\n",
      "Epoch 501/600\n",
      "712/712 [==============================] - 0s 76us/sample - loss: 2.9324 - acc: 0.0899 - val_loss: 2.9360 - val_acc: 0.1180\n",
      "Epoch 502/600\n",
      "712/712 [==============================] - 0s 69us/sample - loss: 2.9324 - acc: 0.0899 - val_loss: 2.9359 - val_acc: 0.1180\n",
      "Epoch 503/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9323 - acc: 0.0899 - val_loss: 2.9359 - val_acc: 0.1180\n",
      "Epoch 504/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9323 - acc: 0.0899 - val_loss: 2.9358 - val_acc: 0.1180\n",
      "Epoch 505/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9323 - acc: 0.0899 - val_loss: 2.9358 - val_acc: 0.1180\n",
      "Epoch 506/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9323 - acc: 0.0899 - val_loss: 2.9357 - val_acc: 0.1180\n",
      "Epoch 507/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9323 - acc: 0.0899 - val_loss: 2.9357 - val_acc: 0.1180\n",
      "Epoch 508/600\n",
      "712/712 [==============================] - 0s 75us/sample - loss: 2.9322 - acc: 0.0899 - val_loss: 2.9356 - val_acc: 0.1180\n",
      "Epoch 509/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9322 - acc: 0.0899 - val_loss: 2.9356 - val_acc: 0.1180\n",
      "Epoch 510/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9322 - acc: 0.0899 - val_loss: 2.9356 - val_acc: 0.1180\n",
      "Epoch 511/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9322 - acc: 0.0899 - val_loss: 2.9356 - val_acc: 0.1180\n",
      "Epoch 512/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9322 - acc: 0.0899 - val_loss: 2.9355 - val_acc: 0.1180\n",
      "Epoch 513/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9322 - acc: 0.0899 - val_loss: 2.9355 - val_acc: 0.1180\n",
      "Epoch 514/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9321 - acc: 0.0899 - val_loss: 2.9354 - val_acc: 0.1180\n",
      "Epoch 515/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9321 - acc: 0.0899 - val_loss: 2.9354 - val_acc: 0.1180\n",
      "Epoch 516/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9321 - acc: 0.0899 - val_loss: 2.9353 - val_acc: 0.1180\n",
      "Epoch 517/600\n",
      "712/712 [==============================] - 0s 72us/sample - loss: 2.9321 - acc: 0.0899 - val_loss: 2.9353 - val_acc: 0.1180\n",
      "Epoch 518/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9321 - acc: 0.0899 - val_loss: 2.9353 - val_acc: 0.1180\n",
      "Epoch 519/600\n",
      "712/712 [==============================] - 0s 72us/sample - loss: 2.9320 - acc: 0.0899 - val_loss: 2.9352 - val_acc: 0.1180\n",
      "Epoch 520/600\n",
      "712/712 [==============================] - 0s 70us/sample - loss: 2.9320 - acc: 0.0899 - val_loss: 2.9352 - val_acc: 0.1180\n",
      "Epoch 521/600\n",
      "712/712 [==============================] - 0s 72us/sample - loss: 2.9320 - acc: 0.0899 - val_loss: 2.9352 - val_acc: 0.1180\n",
      "Epoch 522/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9320 - acc: 0.0899 - val_loss: 2.9352 - val_acc: 0.1180\n",
      "Epoch 523/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9320 - acc: 0.0899 - val_loss: 2.9351 - val_acc: 0.1180\n",
      "Epoch 524/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9320 - acc: 0.0899 - val_loss: 2.9351 - val_acc: 0.1180\n",
      "Epoch 525/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9319 - acc: 0.0899 - val_loss: 2.9350 - val_acc: 0.1180\n",
      "Epoch 526/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9319 - acc: 0.0899 - val_loss: 2.9350 - val_acc: 0.1180\n",
      "Epoch 527/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9319 - acc: 0.0899 - val_loss: 2.9350 - val_acc: 0.1180\n",
      "Epoch 528/600\n",
      "712/712 [==============================] - 0s 69us/sample - loss: 2.9319 - acc: 0.0899 - val_loss: 2.9349 - val_acc: 0.1180\n",
      "Epoch 529/600\n",
      "712/712 [==============================] - 0s 73us/sample - loss: 2.9319 - acc: 0.0899 - val_loss: 2.9349 - val_acc: 0.1180\n",
      "Epoch 530/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9319 - acc: 0.0899 - val_loss: 2.9349 - val_acc: 0.1180\n",
      "Epoch 531/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9318 - acc: 0.0899 - val_loss: 2.9349 - val_acc: 0.1180\n",
      "Epoch 532/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9318 - acc: 0.0899 - val_loss: 2.9348 - val_acc: 0.1180\n",
      "Epoch 533/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9318 - acc: 0.0899 - val_loss: 2.9348 - val_acc: 0.1180\n",
      "Epoch 534/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9318 - acc: 0.0899 - val_loss: 2.9348 - val_acc: 0.1180\n",
      "Epoch 535/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9318 - acc: 0.0899 - val_loss: 2.9347 - val_acc: 0.1180\n",
      "Epoch 536/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9317 - acc: 0.0899 - val_loss: 2.9347 - val_acc: 0.1180\n",
      "Epoch 537/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9317 - acc: 0.0899 - val_loss: 2.9347 - val_acc: 0.1180\n",
      "Epoch 538/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9317 - acc: 0.0899 - val_loss: 2.9347 - val_acc: 0.1180\n",
      "Epoch 539/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9317 - acc: 0.0899 - val_loss: 2.9346 - val_acc: 0.1180\n",
      "Epoch 540/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9317 - acc: 0.0899 - val_loss: 2.9346 - val_acc: 0.1180\n",
      "Epoch 541/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9316 - acc: 0.0899 - val_loss: 2.9346 - val_acc: 0.1180\n",
      "Epoch 542/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9316 - acc: 0.0871 - val_loss: 2.9345 - val_acc: 0.1180\n",
      "Epoch 543/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9316 - acc: 0.0871 - val_loss: 2.9345 - val_acc: 0.1180\n",
      "Epoch 544/600\n",
      "712/712 [==============================] - 0s 72us/sample - loss: 2.9316 - acc: 0.0871 - val_loss: 2.9345 - val_acc: 0.1180\n",
      "Epoch 545/600\n",
      "712/712 [==============================] - 0s 70us/sample - loss: 2.9316 - acc: 0.0871 - val_loss: 2.9345 - val_acc: 0.1180\n",
      "Epoch 546/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9316 - acc: 0.0871 - val_loss: 2.9344 - val_acc: 0.1180\n",
      "Epoch 547/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9315 - acc: 0.0871 - val_loss: 2.9344 - val_acc: 0.1180\n",
      "Epoch 548/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9315 - acc: 0.0871 - val_loss: 2.9344 - val_acc: 0.1180\n",
      "Epoch 549/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9315 - acc: 0.0871 - val_loss: 2.9343 - val_acc: 0.1180\n",
      "Epoch 550/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9315 - acc: 0.0871 - val_loss: 2.9343 - val_acc: 0.1180\n",
      "Epoch 551/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9315 - acc: 0.0871 - val_loss: 2.9343 - val_acc: 0.1180\n",
      "Epoch 552/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9314 - acc: 0.0871 - val_loss: 2.9343 - val_acc: 0.1180\n",
      "Epoch 553/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9314 - acc: 0.0871 - val_loss: 2.9342 - val_acc: 0.1180\n",
      "Epoch 554/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9314 - acc: 0.0871 - val_loss: 2.9342 - val_acc: 0.1180\n",
      "Epoch 555/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9314 - acc: 0.0871 - val_loss: 2.9342 - val_acc: 0.1180\n",
      "Epoch 556/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9314 - acc: 0.0871 - val_loss: 2.9341 - val_acc: 0.1180\n",
      "Epoch 557/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9314 - acc: 0.0871 - val_loss: 2.9341 - val_acc: 0.1180\n",
      "Epoch 558/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9314 - acc: 0.0871 - val_loss: 2.9341 - val_acc: 0.1180\n",
      "Epoch 559/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9313 - acc: 0.0871 - val_loss: 2.9341 - val_acc: 0.1180\n",
      "Epoch 560/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9313 - acc: 0.0871 - val_loss: 2.9341 - val_acc: 0.1180\n",
      "Epoch 561/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9313 - acc: 0.0871 - val_loss: 2.9341 - val_acc: 0.1180\n",
      "Epoch 562/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9313 - acc: 0.0871 - val_loss: 2.9340 - val_acc: 0.1180\n",
      "Epoch 563/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9313 - acc: 0.0871 - val_loss: 2.9340 - val_acc: 0.1180\n",
      "Epoch 564/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9313 - acc: 0.0871 - val_loss: 2.9340 - val_acc: 0.1180\n",
      "Epoch 565/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9313 - acc: 0.0857 - val_loss: 2.9340 - val_acc: 0.1180\n",
      "Epoch 566/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9312 - acc: 0.0857 - val_loss: 2.9339 - val_acc: 0.1180\n",
      "Epoch 567/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9312 - acc: 0.0871 - val_loss: 2.9339 - val_acc: 0.1180\n",
      "Epoch 568/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9312 - acc: 0.0857 - val_loss: 2.9339 - val_acc: 0.1180\n",
      "Epoch 569/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9312 - acc: 0.0857 - val_loss: 2.9339 - val_acc: 0.1180\n",
      "Epoch 570/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9312 - acc: 0.0843 - val_loss: 2.9339 - val_acc: 0.1180\n",
      "Epoch 571/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9312 - acc: 0.0857 - val_loss: 2.9338 - val_acc: 0.1180\n",
      "Epoch 572/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9311 - acc: 0.0857 - val_loss: 2.9338 - val_acc: 0.1180\n",
      "Epoch 573/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9311 - acc: 0.0843 - val_loss: 2.9338 - val_acc: 0.1180\n",
      "Epoch 574/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9311 - acc: 0.0843 - val_loss: 2.9337 - val_acc: 0.1180\n",
      "Epoch 575/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9311 - acc: 0.0843 - val_loss: 2.9337 - val_acc: 0.1180\n",
      "Epoch 576/600\n",
      "712/712 [==============================] - 0s 75us/sample - loss: 2.9311 - acc: 0.0843 - val_loss: 2.9337 - val_acc: 0.1180\n",
      "Epoch 577/600\n",
      "712/712 [==============================] - 0s 68us/sample - loss: 2.9311 - acc: 0.0829 - val_loss: 2.9336 - val_acc: 0.1180\n",
      "Epoch 578/600\n",
      "712/712 [==============================] - 0s 71us/sample - loss: 2.9310 - acc: 0.0829 - val_loss: 2.9336 - val_acc: 0.1180\n",
      "Epoch 579/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9310 - acc: 0.0815 - val_loss: 2.9336 - val_acc: 0.1180\n",
      "Epoch 580/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9310 - acc: 0.0815 - val_loss: 2.9336 - val_acc: 0.1180\n",
      "Epoch 581/600\n",
      "712/712 [==============================] - 0s 70us/sample - loss: 2.9310 - acc: 0.0815 - val_loss: 2.9335 - val_acc: 0.1180\n",
      "Epoch 582/600\n",
      "712/712 [==============================] - 0s 70us/sample - loss: 2.9310 - acc: 0.0815 - val_loss: 2.9335 - val_acc: 0.1180\n",
      "Epoch 583/600\n",
      "712/712 [==============================] - 0s 70us/sample - loss: 2.9310 - acc: 0.0815 - val_loss: 2.9335 - val_acc: 0.1180\n",
      "Epoch 584/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9309 - acc: 0.0815 - val_loss: 2.9335 - val_acc: 0.1180\n",
      "Epoch 585/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9309 - acc: 0.0801 - val_loss: 2.9335 - val_acc: 0.1180\n",
      "Epoch 586/600\n",
      "712/712 [==============================] - 0s 66us/sample - loss: 2.9309 - acc: 0.0815 - val_loss: 2.9334 - val_acc: 0.1180\n",
      "Epoch 587/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9309 - acc: 0.0815 - val_loss: 2.9334 - val_acc: 0.1180\n",
      "Epoch 588/600\n",
      "712/712 [==============================] - 0s 65us/sample - loss: 2.9309 - acc: 0.0801 - val_loss: 2.9334 - val_acc: 0.1180\n",
      "Epoch 589/600\n",
      "712/712 [==============================] - 0s 60us/sample - loss: 2.9309 - acc: 0.0801 - val_loss: 2.9334 - val_acc: 0.1180\n",
      "Epoch 590/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9308 - acc: 0.0801 - val_loss: 2.9333 - val_acc: 0.1180\n",
      "Epoch 591/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9308 - acc: 0.0801 - val_loss: 2.9333 - val_acc: 0.1180\n",
      "Epoch 592/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9308 - acc: 0.0801 - val_loss: 2.9333 - val_acc: 0.1180\n",
      "Epoch 593/600\n",
      "712/712 [==============================] - 0s 61us/sample - loss: 2.9308 - acc: 0.0801 - val_loss: 2.9332 - val_acc: 0.1180\n",
      "Epoch 594/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9308 - acc: 0.0801 - val_loss: 2.9332 - val_acc: 0.1180\n",
      "Epoch 595/600\n",
      "712/712 [==============================] - 0s 67us/sample - loss: 2.9307 - acc: 0.0801 - val_loss: 2.9332 - val_acc: 0.1180\n",
      "Epoch 596/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9307 - acc: 0.0801 - val_loss: 2.9332 - val_acc: 0.1180\n",
      "Epoch 597/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9307 - acc: 0.0801 - val_loss: 2.9332 - val_acc: 0.1180\n",
      "Epoch 598/600\n",
      "712/712 [==============================] - 0s 62us/sample - loss: 2.9307 - acc: 0.0801 - val_loss: 2.9331 - val_acc: 0.1180\n",
      "Epoch 599/600\n",
      "712/712 [==============================] - 0s 64us/sample - loss: 2.9307 - acc: 0.0801 - val_loss: 2.9331 - val_acc: 0.1180\n",
      "Epoch 600/600\n",
      "712/712 [==============================] - 0s 63us/sample - loss: 2.9306 - acc: 0.0801 - val_loss: 2.9331 - val_acc: 0.1180\n"
     ]
    }
   ],
   "source": [
    "# Epochs number of loop over the model\n",
    "fit_history = model.fit(X_train, y_train, \n",
    "                        epochs = 600, \n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fit_history.history['acc'])\n",
    "plt.plot(fit_history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(fit_history.history['loss'])\n",
    "plt.plot(fit_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('pokemon_so_deep/pokemon_multi_layer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
